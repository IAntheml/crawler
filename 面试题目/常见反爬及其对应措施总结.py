"""
1. 通过user-agent来判断是否是爬虫
通过伪装请求头中的user-agent来解决。若user-agent被检测到，可以找一些常见的的user-agent放入列表，然后每次爬取随机选一个。
2. 通过访问频率来判断是否是一个爬虫
设置请求时间间隔
3. 爬取频繁将IP进行封禁
代理IP池子
4. 验证码反爬
①简单的图形验证码：可以使用tesseract来处理，也可以使用最新的一个muggle_ocr来处理，识别率还凑合。对于复杂的可以去打码平台。
②滑块验证码：通过selenium+浏览器获取滑块的滑动间距，然后捕捉滑块按钮，按照人体的规律（一般是先快后慢）拖动滑块
③其他验证码：打码平台解决
5. cookie反爬
主要有两种方式：一种是web访问服务器，服务器返回cookie；另一种是web访问服务器，服务器返回js，前端执行JS生产Cookie
6. 签名参数（JS）
JS生成一些动态的签名参数访问服务器，服务器检测。
"""
